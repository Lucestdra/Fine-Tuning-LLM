# Fine-Tuning-LLM
This repository contains a Python implementation for fine-tuning a Llama language model using the LoRA (Low-Rank Adaptation) technique and 4-bit quantization for memory efficiency. The fine-tuned model is trained on a medical terms dataset and can be used for generating context-aware text responses.
